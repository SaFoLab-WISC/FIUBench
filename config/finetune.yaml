model_id: liuhaotian/llava-v1.6-vicuna-7b
model_family: vicuna-7b-v1.5

LoRA:
  r: 8
  alpha: 32
  dropout: 0.05

data_path: /home/scratch.chaoweix_nvresearch/av/VLM_Unlearned/dataset
split: full
batch_size: 16
gradient_accumulation_steps: 1
num_epochs: 10
save_dir: paper_models/final_ft_LORA_${num_epochs}_epochs_inst_lr${lr}_${model_family}_${split}
lr: 1e-4
weight_decay: 0