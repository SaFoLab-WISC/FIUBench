# VFUBench: Benchmarking Vision Language Model Unlearning via Fictious Datasets

We introduce **VFUBench**, a new benchmark designed to robustly evaluate VLM unlearning, especially under the **Right to be Forgotten** setting. This benchmark is built on our newly developed Fictitious Entity Visual Question Answering (VQA) dataset, which includes 400 virtual entities, each represented through 20 VQAs focusing on image-related attributes and background knowledge. 
